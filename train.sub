universe        = vanilla
executable      = run.sh
arguments       = $(SCRIPT)

# Transfer your code + wrapper + the two inputs from /home
transfer_input_files = run.sh, train_script, syn_HI_spec_z.tar.gz, fcnm_RHI_z.fits
transfer_output_files = results, figs


# THIS is the Docker image (run via Apptainer on CHTC)
container_image = docker://pytorch/pytorch:2.3.1-cuda12.1-cudnn8-runtime

# Request a GPU + reasonable CPU/RAM
request_gpus    = 1
request_cpus    = 8
request_memory  = 24GB
request_disk    = 40GB

# Logs
output          = /home/hchen792/ML_MW/ML/logs/$(SCRIPT).$(ClusterId).$(ProcId).out
error           = /home/hchen792/ML_MW/ML/logs/$(SCRIPT).$(ClusterId).$(ProcId).err
log             = /home/hchen792/ML_MW/ML/logs/$(ClusterId).log

should_transfer_files   = YES
when_to_transfer_output = ON_EXIT
+PreferSingularity = True


# launch 3 jobs with different SCRIPT values
queue SCRIPT in ml_6.py, ml_7.py
